{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exoplanets - Data Modelling\n",
    "\n",
    "In this notebook we will model the data provided in the dataset and evaluate the results. After the implementation of data-loading fuctions, two models will be used to evaluate how different algorimths classify the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime, os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# custom code\n",
    "from utils import data_loader_txt, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SET_PATH = \"/data/Exoplanets/exoTrain.csv\"\n",
    "TEST_SET_PATH = \"data/Exoplanets/exoTest.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define label column\n",
    "LABEL_COLUMN_INDEX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train set\n",
    "x_train, y_train = data_loader_txt(path=TRAIN_SET_PATH, label_column_index=LABEL_COLUMN_INDEX) \n",
    "# loading test set\n",
    "x_test, y_test = data_loader_txt(path=TEST_SET_PATH,label_column_index=LABEL_COLUMN_INDEX) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(C=0.5, max_iter=3000, verbose=0,  class_weight='balanced')\n",
    "print(\"SVC - baseline training...\")\n",
    "svc.fit(x_train, np.squeeze(y_train))\n",
    "y_pred = svc.predict(x_test)\n",
    "print(\"SVC - training and evaluation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculare confusion matrix\n",
    "scv_cm = confusion_matrix(y_true=np.squeeze(y_test), y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(scv_cm, [\"Non-Exoplanet\", \"Exoplanet\"], normalize=False)\n",
    "print(\"Recall score:\",recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python m gcp_ai_platform_job/task.py \\\n",
    "    --train_data_path=${TRAIN_SET_PATH} \\\n",
    "    --eval_data_path=${TEST_SET_PATH} \\\n",
    "    --output_dir=${OUTDIR} \\\n",
    "    --num_epochs=5 \\\n",
    "    --batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two models have been implemeted in this notebook a SVC and a (small) CNN. The results prove that the CNN did worked better than the SVC. Nevertheless, some remarks are reported below:\n",
    "\n",
    "- SVC could improve its performances by working on a smaller set of engineered features.\n",
    "- CNN should be did archive respectivelly 81% and 100% of recall in train and test set. Since the test set is actually quite small it might makes sense to revaluate the results with a different split i.e cross-validation.\n",
    "- No specific HPO has been performed. That's could improve the results/robustness of both algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
