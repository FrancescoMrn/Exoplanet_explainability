{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exoplanets - Data Modelling\n",
    "\n",
    "In this notebook we will model the data provided in the dataset and evaluate the results. After the implementation of data-loading fuctions, two models will be used to evaluate how different algorimths classify the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime, os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SET_PATH = \"data/Exoplanets/exoTrain.csv\"\n",
    "TEST_SET_PATH = \"data/Exoplanets/exoTest.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define label column\n",
    "LABEL_COLUMN_INDEX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_txt(path, skiprows=1, delimiter=',', normalize=True):\n",
    "    raw = np.loadtxt(path, skiprows=1, delimiter=',')\n",
    "    x = raw[:, LABEL_COLUMN_INDEX+1:]\n",
    "    y = raw[:, LABEL_COLUMN_INDEX, np.newaxis] - 1. # -1 to report label in the range 0-1\n",
    "    \n",
    "    if normalize: # standard normalization\n",
    "        x = ((x - np.mean(x, axis=1).reshape(-1,1)) / np.std(x, axis=1).reshape(-1,1))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train set\n",
    "x_train, y_train = data_loader_txt(TRAIN_SET_PATH) \n",
    "# loading test set\n",
    "x_test, y_test = data_loader_txt(TEST_SET_PATH) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC - baseline training...\n",
      "SVC - training and evaluation completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francesco\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(C=0.5, max_iter=3000, verbose=0,  class_weight='balanced')\n",
    "print(\"SVC - baseline training...\")\n",
    "svc.fit(x_train, np.squeeze(y_train))\n",
    "y_pred = svc.predict(x_test)\n",
    "print(\"SVC - training and evaluation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculare confusion matrix\n",
    "scv_cm = confusion_matrix(y_true=np.squeeze(y_test), y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\n \\nAccuracy={:0.3f}; Missclass={:0.3f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 0.2\n"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(scv_cm, [\"Non-Exoplanet\", \"Exoplanet\"], normalize=False)\n",
    "print(\"Recall score:\",recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Dense, Dropout, Flatten, BatchNormalization, Input, concatenate, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand one dimension to work with 1D CNN layer\n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "        Conv1D(filters=8, kernel_size=5, activation='relu', input_shape=x_train.shape[1:]),\n",
    "        MaxPool1D(strides=4),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(filters=16, kernel_size=3, activation='relu'),\n",
    "        MaxPool1D(strides=4),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "        MaxPool1D(strides=4),\n",
    "        BatchNormalization(),\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "        MaxPool1D(strides=4),\n",
    "        Flatten(),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(x_train, y_train, batch_size=32):\n",
    "    \"\"\"\n",
    "    Gives equal number of positive and negative samples, and rotates them randomly in time\n",
    "    \"\"\"\n",
    "    half_batch = batch_size // 2\n",
    "    x_batch = np.empty((batch_size, x_train.shape[1], x_train.shape[2]), dtype='float32')\n",
    "    y_batch = np.empty((batch_size, y_train.shape[1]), dtype='float32')\n",
    "    \n",
    "    yes_idx = np.where(y_train[:,0] == 1.)[0]\n",
    "    non_idx = np.where(y_train[:,0] == 0.)[0]\n",
    "    \n",
    "    while True:\n",
    "        np.random.shuffle(yes_idx)\n",
    "        np.random.shuffle(non_idx)\n",
    "    \n",
    "        x_batch[:half_batch] = x_train[yes_idx[:half_batch]]\n",
    "        x_batch[half_batch:] = x_train[non_idx[half_batch:batch_size]]\n",
    "        y_batch[:half_batch] = y_train[yes_idx[:half_batch]]\n",
    "        y_batch[half_batch:] = y_train[non_idx[half_batch:batch_size]]\n",
    "    \n",
    "        for i in range(batch_size):\n",
    "            sz = np.random.randint(x_batch.shape[1])\n",
    "            x_batch[i] = np.roll(x_batch[i], sz, axis = 0)\n",
    "     \n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model compile and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, batch_size=32):\n",
    "    model = create_model()\n",
    "    print(\"Model architecture in training:\")\n",
    "    print(model.summary())\n",
    "    print(\"\\n\")\n",
    "    model.compile(optimizer=Adam(3e-5),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "    model.fit(batch_generator(x_train, y_train, batch_size), \n",
    "              epochs=epochs, \n",
    "              validation_data=(x_test, y_test),\n",
    "              steps_per_epoch=x_train.shape[1]//batch_size,\n",
    "              callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture in training:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 3193, 8)           48        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 798, 8)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 798, 8)            32        \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 796, 16)           400       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 199, 16)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 199, 16)           64        \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 197, 32)           1568      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 49, 32)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 49, 32)            128       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 47, 64)            6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 12, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                49216     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 61,889\n",
      "Trainable params: 61,777\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      " 1/99 [..............................] - ETA: 0s - loss: 0.7722 - binary_accuracy: 0.5625 - recall: 0.8750WARNING:tensorflow:From C:\\Users\\Francesco\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/99 [..............................] - ETA: 2s - loss: 0.7999 - binary_accuracy: 0.5312 - recall: 0.9062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.0500s). Check your callbacks.\n",
      "99/99 [==============================] - 1s 10ms/step - loss: 0.7525 - binary_accuracy: 0.5360 - recall: 0.6559 - val_loss: 0.6959 - val_binary_accuracy: 0.4825 - val_recall: 0.8000\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6954 - binary_accuracy: 0.5789 - recall: 0.5309 - val_loss: 0.7168 - val_binary_accuracy: 0.4614 - val_recall: 0.8000\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6797 - binary_accuracy: 0.5906 - recall: 0.5568 - val_loss: 0.6643 - val_binary_accuracy: 0.6158 - val_recall: 0.8000\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6504 - binary_accuracy: 0.6218 - recall: 0.5783 - val_loss: 0.5997 - val_binary_accuracy: 0.7193 - val_recall: 0.8000\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6411 - binary_accuracy: 0.6424 - recall: 0.6168 - val_loss: 0.5557 - val_binary_accuracy: 0.7526 - val_recall: 0.8000\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6440 - binary_accuracy: 0.6313 - recall: 0.6193 - val_loss: 0.5382 - val_binary_accuracy: 0.7684 - val_recall: 0.6000\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6341 - binary_accuracy: 0.6430 - recall: 0.6326 - val_loss: 0.5252 - val_binary_accuracy: 0.7789 - val_recall: 0.6000\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6278 - binary_accuracy: 0.6449 - recall: 0.6218 - val_loss: 0.5150 - val_binary_accuracy: 0.7877 - val_recall: 0.6000\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6086 - binary_accuracy: 0.6698 - recall: 0.6572 - val_loss: 0.5120 - val_binary_accuracy: 0.7860 - val_recall: 0.6000\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6189 - binary_accuracy: 0.6641 - recall: 0.6503 - val_loss: 0.5351 - val_binary_accuracy: 0.7579 - val_recall: 0.6000\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.6160 - binary_accuracy: 0.6607 - recall: 0.6547 - val_loss: 0.5128 - val_binary_accuracy: 0.7702 - val_recall: 0.6000\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.5997 - binary_accuracy: 0.6837 - recall: 0.6894 - val_loss: 0.5066 - val_binary_accuracy: 0.7737 - val_recall: 0.6000\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.5959 - binary_accuracy: 0.6859 - recall: 0.6843 - val_loss: 0.5043 - val_binary_accuracy: 0.7702 - val_recall: 0.6000\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5997 - binary_accuracy: 0.6837 - recall: 0.6862 - val_loss: 0.5114 - val_binary_accuracy: 0.7579 - val_recall: 0.6000\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5914 - binary_accuracy: 0.6843 - recall: 0.6843 - val_loss: 0.5203 - val_binary_accuracy: 0.7544 - val_recall: 0.6000\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5818 - binary_accuracy: 0.6926 - recall: 0.6989 - val_loss: 0.5076 - val_binary_accuracy: 0.7596 - val_recall: 0.6000\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5782 - binary_accuracy: 0.7083 - recall: 0.7172 - val_loss: 0.5178 - val_binary_accuracy: 0.7491 - val_recall: 0.6000\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5829 - binary_accuracy: 0.6944 - recall: 0.7121 - val_loss: 0.5193 - val_binary_accuracy: 0.7386 - val_recall: 0.6000\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5905 - binary_accuracy: 0.6888 - recall: 0.7071 - val_loss: 0.5195 - val_binary_accuracy: 0.7386 - val_recall: 0.6000\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5728 - binary_accuracy: 0.7112 - recall: 0.7311 - val_loss: 0.5076 - val_binary_accuracy: 0.7421 - val_recall: 0.6000\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5754 - binary_accuracy: 0.7027 - recall: 0.7229 - val_loss: 0.5110 - val_binary_accuracy: 0.7421 - val_recall: 0.6000\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5773 - binary_accuracy: 0.7042 - recall: 0.7197 - val_loss: 0.5052 - val_binary_accuracy: 0.7386 - val_recall: 0.6000\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5600 - binary_accuracy: 0.7175 - recall: 0.7247 - val_loss: 0.5096 - val_binary_accuracy: 0.7351 - val_recall: 0.6000\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5644 - binary_accuracy: 0.7197 - recall: 0.7393 - val_loss: 0.5100 - val_binary_accuracy: 0.7316 - val_recall: 0.6000\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5689 - binary_accuracy: 0.7033 - recall: 0.7361 - val_loss: 0.4997 - val_binary_accuracy: 0.7421 - val_recall: 0.6000\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.5616 - binary_accuracy: 0.7115 - recall: 0.7519 - val_loss: 0.5040 - val_binary_accuracy: 0.7333 - val_recall: 0.6000\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5658 - binary_accuracy: 0.7162 - recall: 0.7437 - val_loss: 0.5035 - val_binary_accuracy: 0.7298 - val_recall: 0.6000\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5795 - binary_accuracy: 0.6998 - recall: 0.7361 - val_loss: 0.4999 - val_binary_accuracy: 0.7351 - val_recall: 0.6000\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5709 - binary_accuracy: 0.6973 - recall: 0.7266 - val_loss: 0.4944 - val_binary_accuracy: 0.7333 - val_recall: 0.6000\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5604 - binary_accuracy: 0.7159 - recall: 0.7494 - val_loss: 0.4988 - val_binary_accuracy: 0.7298 - val_recall: 0.6000\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5637 - binary_accuracy: 0.7093 - recall: 0.7487 - val_loss: 0.4928 - val_binary_accuracy: 0.7316 - val_recall: 0.6000\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5581 - binary_accuracy: 0.7055 - recall: 0.7437 - val_loss: 0.4920 - val_binary_accuracy: 0.7351 - val_recall: 0.8000\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5402 - binary_accuracy: 0.7295 - recall: 0.7652 - val_loss: 0.4846 - val_binary_accuracy: 0.7368 - val_recall: 0.6000\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5430 - binary_accuracy: 0.7336 - recall: 0.7645 - val_loss: 0.4811 - val_binary_accuracy: 0.7386 - val_recall: 0.8000\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5575 - binary_accuracy: 0.7222 - recall: 0.7664 - val_loss: 0.4737 - val_binary_accuracy: 0.7368 - val_recall: 0.8000\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5547 - binary_accuracy: 0.7165 - recall: 0.7386 - val_loss: 0.4914 - val_binary_accuracy: 0.7298 - val_recall: 0.8000\n",
      "Epoch 37/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5566 - binary_accuracy: 0.7194 - recall: 0.7551 - val_loss: 0.4897 - val_binary_accuracy: 0.7281 - val_recall: 0.8000\n",
      "Epoch 38/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5511 - binary_accuracy: 0.7181 - recall: 0.7525 - val_loss: 0.4840 - val_binary_accuracy: 0.7333 - val_recall: 0.8000\n",
      "Epoch 39/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5491 - binary_accuracy: 0.7178 - recall: 0.7544 - val_loss: 0.4826 - val_binary_accuracy: 0.7351 - val_recall: 0.8000\n",
      "Epoch 40/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5362 - binary_accuracy: 0.7307 - recall: 0.7551 - val_loss: 0.5008 - val_binary_accuracy: 0.7298 - val_recall: 0.8000\n",
      "Epoch 41/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5429 - binary_accuracy: 0.7260 - recall: 0.7727 - val_loss: 0.4817 - val_binary_accuracy: 0.7333 - val_recall: 0.8000\n",
      "Epoch 42/100\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.5331 - binary_accuracy: 0.7311 - recall: 0.7708 - val_loss: 0.4792 - val_binary_accuracy: 0.7333 - val_recall: 0.8000\n",
      "Epoch 43/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5424 - binary_accuracy: 0.7263 - recall: 0.7563 - val_loss: 0.4762 - val_binary_accuracy: 0.7316 - val_recall: 0.8000\n",
      "Epoch 44/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5265 - binary_accuracy: 0.7336 - recall: 0.7727 - val_loss: 0.4844 - val_binary_accuracy: 0.7246 - val_recall: 0.8000\n",
      "Epoch 45/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5256 - binary_accuracy: 0.7336 - recall: 0.7702 - val_loss: 0.4779 - val_binary_accuracy: 0.7351 - val_recall: 0.8000\n",
      "Epoch 46/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5236 - binary_accuracy: 0.7361 - recall: 0.7715 - val_loss: 0.4825 - val_binary_accuracy: 0.7333 - val_recall: 0.8000\n",
      "Epoch 47/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5283 - binary_accuracy: 0.7307 - recall: 0.7670 - val_loss: 0.4650 - val_binary_accuracy: 0.7404 - val_recall: 0.8000\n",
      "Epoch 48/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5386 - binary_accuracy: 0.7244 - recall: 0.7614 - val_loss: 0.4515 - val_binary_accuracy: 0.7439 - val_recall: 0.8000\n",
      "Epoch 49/100\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 0.5246 - binary_accuracy: 0.7323 - recall: 0.7576 - val_loss: 0.4677 - val_binary_accuracy: 0.7351 - val_recall: 0.8000\n",
      "Epoch 50/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5322 - binary_accuracy: 0.7292 - recall: 0.7658 - val_loss: 0.4656 - val_binary_accuracy: 0.7333 - val_recall: 0.8000\n",
      "Epoch 51/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5255 - binary_accuracy: 0.7380 - recall: 0.7715 - val_loss: 0.4744 - val_binary_accuracy: 0.7316 - val_recall: 0.8000\n",
      "Epoch 52/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5241 - binary_accuracy: 0.7336 - recall: 0.7740 - val_loss: 0.4721 - val_binary_accuracy: 0.7316 - val_recall: 0.8000\n",
      "Epoch 53/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5203 - binary_accuracy: 0.7330 - recall: 0.7683 - val_loss: 0.4613 - val_binary_accuracy: 0.7351 - val_recall: 0.8000\n",
      "Epoch 54/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5229 - binary_accuracy: 0.7352 - recall: 0.7721 - val_loss: 0.4554 - val_binary_accuracy: 0.7404 - val_recall: 0.8000\n",
      "Epoch 55/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5363 - binary_accuracy: 0.7188 - recall: 0.7513 - val_loss: 0.4654 - val_binary_accuracy: 0.7263 - val_recall: 0.8000\n",
      "Epoch 56/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5122 - binary_accuracy: 0.7405 - recall: 0.7670 - val_loss: 0.4722 - val_binary_accuracy: 0.7228 - val_recall: 0.8000\n",
      "Epoch 57/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5288 - binary_accuracy: 0.7257 - recall: 0.7519 - val_loss: 0.4648 - val_binary_accuracy: 0.7263 - val_recall: 0.8000\n",
      "Epoch 58/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5176 - binary_accuracy: 0.7342 - recall: 0.7689 - val_loss: 0.4607 - val_binary_accuracy: 0.7246 - val_recall: 0.8000\n",
      "Epoch 59/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5232 - binary_accuracy: 0.7333 - recall: 0.7645 - val_loss: 0.4633 - val_binary_accuracy: 0.7228 - val_recall: 0.8000\n",
      "Epoch 60/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5179 - binary_accuracy: 0.7431 - recall: 0.7727 - val_loss: 0.4722 - val_binary_accuracy: 0.7193 - val_recall: 0.8000\n",
      "Epoch 61/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4997 - binary_accuracy: 0.7421 - recall: 0.7841 - val_loss: 0.4629 - val_binary_accuracy: 0.7228 - val_recall: 0.8000\n",
      "Epoch 62/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5141 - binary_accuracy: 0.7358 - recall: 0.7765 - val_loss: 0.4583 - val_binary_accuracy: 0.7316 - val_recall: 0.8000\n",
      "Epoch 63/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4947 - binary_accuracy: 0.7491 - recall: 0.7803 - val_loss: 0.4566 - val_binary_accuracy: 0.7333 - val_recall: 0.8000\n",
      "Epoch 64/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4969 - binary_accuracy: 0.7475 - recall: 0.7822 - val_loss: 0.4468 - val_binary_accuracy: 0.7421 - val_recall: 0.8000\n",
      "Epoch 65/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5062 - binary_accuracy: 0.7396 - recall: 0.7670 - val_loss: 0.4558 - val_binary_accuracy: 0.7298 - val_recall: 0.8000\n",
      "Epoch 66/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5046 - binary_accuracy: 0.7446 - recall: 0.7677 - val_loss: 0.4530 - val_binary_accuracy: 0.7246 - val_recall: 0.8000\n",
      "Epoch 67/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5046 - binary_accuracy: 0.7339 - recall: 0.7721 - val_loss: 0.4476 - val_binary_accuracy: 0.7281 - val_recall: 0.8000\n",
      "Epoch 68/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4945 - binary_accuracy: 0.7532 - recall: 0.7936 - val_loss: 0.4289 - val_binary_accuracy: 0.7491 - val_recall: 0.8000\n",
      "Epoch 69/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5047 - binary_accuracy: 0.7494 - recall: 0.7771 - val_loss: 0.4580 - val_binary_accuracy: 0.7333 - val_recall: 1.0000\n",
      "Epoch 70/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4770 - binary_accuracy: 0.7677 - recall: 0.8056 - val_loss: 0.4544 - val_binary_accuracy: 0.7316 - val_recall: 0.8000\n",
      "Epoch 71/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4917 - binary_accuracy: 0.7487 - recall: 0.7847 - val_loss: 0.4303 - val_binary_accuracy: 0.7491 - val_recall: 0.8000\n",
      "Epoch 72/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4921 - binary_accuracy: 0.7551 - recall: 0.7929 - val_loss: 0.4440 - val_binary_accuracy: 0.7456 - val_recall: 1.0000\n",
      "Epoch 73/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4935 - binary_accuracy: 0.7522 - recall: 0.7778 - val_loss: 0.4455 - val_binary_accuracy: 0.7421 - val_recall: 1.0000\n",
      "Epoch 74/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4945 - binary_accuracy: 0.7424 - recall: 0.7753 - val_loss: 0.4338 - val_binary_accuracy: 0.7544 - val_recall: 1.0000\n",
      "Epoch 75/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.5036 - binary_accuracy: 0.7431 - recall: 0.7734 - val_loss: 0.4425 - val_binary_accuracy: 0.7509 - val_recall: 1.0000\n",
      "Epoch 76/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4813 - binary_accuracy: 0.7595 - recall: 0.7891 - val_loss: 0.4431 - val_binary_accuracy: 0.7509 - val_recall: 1.0000\n",
      "Epoch 77/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4834 - binary_accuracy: 0.7610 - recall: 0.7904 - val_loss: 0.4241 - val_binary_accuracy: 0.7649 - val_recall: 1.0000\n",
      "Epoch 78/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4731 - binary_accuracy: 0.7614 - recall: 0.7847 - val_loss: 0.4446 - val_binary_accuracy: 0.7456 - val_recall: 1.0000\n",
      "Epoch 79/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4730 - binary_accuracy: 0.7576 - recall: 0.7898 - val_loss: 0.4317 - val_binary_accuracy: 0.7561 - val_recall: 0.8000\n",
      "Epoch 80/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4682 - binary_accuracy: 0.7689 - recall: 0.7860 - val_loss: 0.4417 - val_binary_accuracy: 0.7474 - val_recall: 1.0000\n",
      "Epoch 81/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4743 - binary_accuracy: 0.7617 - recall: 0.7917 - val_loss: 0.4500 - val_binary_accuracy: 0.7474 - val_recall: 1.0000\n",
      "Epoch 82/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4732 - binary_accuracy: 0.7683 - recall: 0.7980 - val_loss: 0.4288 - val_binary_accuracy: 0.7684 - val_recall: 1.0000\n",
      "Epoch 83/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4708 - binary_accuracy: 0.7693 - recall: 0.7948 - val_loss: 0.4360 - val_binary_accuracy: 0.7632 - val_recall: 1.0000\n",
      "Epoch 84/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4633 - binary_accuracy: 0.7784 - recall: 0.8138 - val_loss: 0.4369 - val_binary_accuracy: 0.7614 - val_recall: 1.0000\n",
      "Epoch 85/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4627 - binary_accuracy: 0.7721 - recall: 0.8005 - val_loss: 0.4272 - val_binary_accuracy: 0.7667 - val_recall: 1.0000\n",
      "Epoch 86/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4555 - binary_accuracy: 0.7759 - recall: 0.7999 - val_loss: 0.4383 - val_binary_accuracy: 0.7579 - val_recall: 1.0000\n",
      "Epoch 87/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4761 - binary_accuracy: 0.7689 - recall: 0.8068 - val_loss: 0.4262 - val_binary_accuracy: 0.7649 - val_recall: 1.0000\n",
      "Epoch 88/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4650 - binary_accuracy: 0.7674 - recall: 0.7967 - val_loss: 0.4338 - val_binary_accuracy: 0.7632 - val_recall: 1.0000\n",
      "Epoch 89/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4655 - binary_accuracy: 0.7655 - recall: 0.7992 - val_loss: 0.4213 - val_binary_accuracy: 0.7702 - val_recall: 1.0000\n",
      "Epoch 90/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4710 - binary_accuracy: 0.7670 - recall: 0.7917 - val_loss: 0.4353 - val_binary_accuracy: 0.7579 - val_recall: 1.0000\n",
      "Epoch 91/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4484 - binary_accuracy: 0.7841 - recall: 0.8188 - val_loss: 0.4368 - val_binary_accuracy: 0.7596 - val_recall: 1.0000\n",
      "Epoch 92/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4531 - binary_accuracy: 0.7901 - recall: 0.8270 - val_loss: 0.4287 - val_binary_accuracy: 0.7649 - val_recall: 1.0000\n",
      "Epoch 93/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4511 - binary_accuracy: 0.7847 - recall: 0.8226 - val_loss: 0.4188 - val_binary_accuracy: 0.7702 - val_recall: 1.0000\n",
      "Epoch 94/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4405 - binary_accuracy: 0.7841 - recall: 0.8138 - val_loss: 0.4234 - val_binary_accuracy: 0.7632 - val_recall: 1.0000\n",
      "Epoch 95/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4417 - binary_accuracy: 0.7863 - recall: 0.8188 - val_loss: 0.4128 - val_binary_accuracy: 0.7754 - val_recall: 1.0000\n",
      "Epoch 96/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4450 - binary_accuracy: 0.7898 - recall: 0.8258 - val_loss: 0.4201 - val_binary_accuracy: 0.7754 - val_recall: 1.0000\n",
      "Epoch 97/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4482 - binary_accuracy: 0.7860 - recall: 0.8093 - val_loss: 0.4115 - val_binary_accuracy: 0.7825 - val_recall: 1.0000\n",
      "Epoch 98/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4361 - binary_accuracy: 0.7992 - recall: 0.8270 - val_loss: 0.4125 - val_binary_accuracy: 0.7807 - val_recall: 1.0000\n",
      "Epoch 99/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4321 - binary_accuracy: 0.7917 - recall: 0.8232 - val_loss: 0.4104 - val_binary_accuracy: 0.7807 - val_recall: 1.0000\n",
      "Epoch 100/100\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 0.4418 - binary_accuracy: 0.7869 - recall: 0.8112 - val_loss: 0.4251 - val_binary_accuracy: 0.7772 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train_model(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20036), started 0:01:33 ago. (Use '!kill 20036' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e9ffb7faaaa953b9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e9ffb7faaaa953b9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two models have been implemeted in this notebook a SVC and a (small) CNN. The results prove that the CNN did worked better than the SVC. Nevertheless, some remarks are reported below:\n",
    "\n",
    "- SVC could improve its performances by working on a smaller set of engineered features.\n",
    "- CNN should be did archive respectivelly 81% and 100% of recall in train and test set. Since the test set is actually quite small it might makes sense to revaluate the results with a different split i.e cross-validation.\n",
    "- No specific HPO has been performed. That's could improve the results/robustness of both algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
